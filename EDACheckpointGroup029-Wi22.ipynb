{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - EDA Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Clara Yi\n",
    "- Ernest Lin\n",
    "- Wesley Nguyen\n",
    "- Ethan Lee\n",
    "- Stephen Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the macroscopic socioeconomic features of a state, specifically median income, percentage of population without health insurance, and prevalence of blue collar workers, have a correlation to COVID infection and mortality rates in 2020-2021?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these installations are not directly related to our EDA, but the necessary packages throughout all steps of our project. There are EDA-specific installations later.\n",
    "# pip initial installation\n",
    "!pip3 install pandas\n",
    "!pip install pandas\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn\n",
    "!pip3 install openpyxl\n",
    "!pip3 install sklearn\n",
    "!pip3 install patsy \n",
    "!pip3 install statsmodels\n",
    "!pip3 install openpyxl\n",
    "\n",
    "#importing necessat libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 (COVID)\n",
    "- With the imported data, we removed unncessary states. We only want the 50 states not including territories or DC\n",
    "- We then removed the columns that we didn't need for analysis. We did this by selecting the columns that we needed\n",
    "- We also wanted the dates to appear in a sortable/searchable way, so we made the dates arranged in yyyy-mm-dd format\n",
    "- The data was then saved as a csv file.\n",
    "\n",
    "**Note**: Since the data is arranged by date, we created a function ```read_covid_data``` that will return the 50 states with their respective data for just that specified date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 (COVID) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning State Data\n",
    "def clean_covid_data():\n",
    "    # Date Closure\n",
    "    def apply_date(date: str) -> str:\n",
    "        split_date = date.split(\"/\")\n",
    "        return \"/\".join([split_date[2], split_date[0], split_date[1]])\n",
    "        \n",
    "    \n",
    "    # Read the data (already in tabular form)\n",
    "    covid_data_url = r\"./Raw Data/United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv\"\n",
    "    covid_data = pd.read_csv(covid_data_url)\n",
    "    \n",
    "    # States we will not be looking at (These aren't part of the 50 states)\n",
    "    remove_states = [\"RMI\", \"FSM\", \"GU\", \"MP\", \"PW\", \"NYC\", \"PR\", \"AS\", \"VI\", \"DC\"]\n",
    "    covid_data = covid_data[~covid_data[\"state\"].isin(remove_states)]\n",
    "    \n",
    "    # Remove columns we don't need\n",
    "    covid_data = covid_data[[\"submission_date\", \"state\", \"tot_cases\", \"tot_death\"]]\n",
    "    \n",
    "    # Change Date format to allow for easier sorting\n",
    "    covid_data[\"submission_date\"] = covid_data[\"submission_date\"].apply(apply_date)\n",
    "    \n",
    "    # Sort Date\n",
    "    covid_data.sort_values(\"submission_date\", inplace=True, ascending=False)\n",
    "    covid_data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Save Data\n",
    "    clean_covid_data_url = r\"Cleaned Data/state_covid_data.csv\"\n",
    "    covid_data.to_csv(clean_covid_data_url, index=False)\n",
    "    \n",
    "clean_covid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_covid_data(month: int, day: int, year: int):\n",
    "    #retrieve cleaned csv\n",
    "    covid_data_url = r\"Cleaned Data/state_covid_data.csv\"\n",
    "    covid_data = pd.read_csv(covid_data_url)\n",
    "    \n",
    "    #reformat date parameter to match data values in csv, then get all data from specific date\n",
    "    date_filter = formatDate(month, day, year)\n",
    "    covid_data = covid_data[covid_data[\"submission_date\"] == date_filter]\n",
    "    covid_data.sort_values(\"state\", inplace=True)\n",
    "    covid_data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return covid_data\n",
    "\n",
    "def formatPreZero(num: int) -> str:\n",
    "\n",
    "    #adds '0' char to any integer less than 10 to match formatting\n",
    "    if num >= 10:\n",
    "        return str(num)\n",
    "    \n",
    "    return \"0\" + str(num)\n",
    "    \n",
    "#reformat date parameter to match data values in csv    \n",
    "def formatDate(month: int,  day: int, year: int) -> str:\n",
    "    return f\"{year}/{formatPreZero(month)}/{formatPreZero(day)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2 (Labor)\n",
    "- The raw data file for Dataset 2 is an excel file. The format of the data was not organized in a way that complements dataframes, so we had a lot of unnecessary texts in the excel\n",
    "read as data entries as well. \n",
    "- Our first step was to identify the columns and rows that we want, which are the 50 states. We removed unnecessary states (including U.S. territories) and removed all the extra\n",
    "non-state entries that were read as rows.\n",
    "- Another problem is that some names in the State column had some footnote numbers that were unintentionally read from the excel sheet. We solved this by removing all occurences of numbers and parentheses from the State column.\n",
    "- Since other datasets use state codes and the original data uses state names, we had to transform state names in the States column to their corresponding state codes. We did this by defining a function ```to_state_code``` that uses a dictionary to map each state name to their state code.\n",
    "- We had to reorganize the structure of the dataframe, as the original file had the data stacked on top of each other so each state had 3 rows in the Dataframe. We did so by separating the \n",
    "raw dataframe into three different dataframes, and then combining them into a single dataframe so we only have 50 rows.\n",
    "- We then removed unnessary columns, such as data from other time periods (Our focus was December of 2020). We also combined the columns of job sectors into two groups relevant to our analysis: Blue collar (construction, mining, trade, leisure) and White collar (Financial, professional, education, government) jobs.\n",
    "- Our final step for Dataset 3 is to export the cleaned dataset as a csv and save it to the \"Cleaned Data\" folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2 (Labor) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copied from https://gist.github.com/rogerallen/1583593\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "}\n",
    "\n",
    "def to_state_code(state_name):\n",
    "    return us_state_to_abbrev[state_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_labor_data():\n",
    "    #Read excel file, renames first column to States and take out null rows\n",
    "    raw_labor_data = pd.read_excel(\"./Raw Data/labor_dataset_raw.xlsx\", header = 4, engine = \"openpyxl\")\n",
    "    raw_labor_data.rename(columns={\"Unnamed: 0\": \"State\"}, inplace=True)\n",
    "    raw_labor_data = raw_labor_data.dropna()\n",
    "\n",
    "    #Take out data from 2021 and only keep 2020\n",
    "    raw_labor_data = raw_labor_data[[\"State\", \"Dec.\\n2020\", \"Dec.\\n2020.1\", \"Dec.\\n2020.2\"]]\n",
    "    \n",
    "    non_states = [\"Virgin Islands\", \"District of Columbia\", \"Puerto Rico\"]\n",
    "\n",
    "    #Removes all non official states from dataset\n",
    "    for region in non_states:\n",
    "        raw_labor_data = raw_labor_data[raw_labor_data[\"State\"].str.contains(region)==False]\n",
    "\n",
    "    #Reset index to start at 0\n",
    "    raw_labor_data = raw_labor_data.reset_index(drop = True)\n",
    "\n",
    "    #eliminated extra characters in state names\n",
    "    raw_labor_data[\"State\"] = raw_labor_data[\"State\"].str.replace('\\d+', '', regex=True)\n",
    "    raw_labor_data[\"State\"] = raw_labor_data[\"State\"].str.replace('(', '', regex=True)\n",
    "    raw_labor_data[\"State\"] = raw_labor_data[\"State\"].str.replace(')', '', regex=True)\n",
    "\n",
    "    #Convert state names into codes (First two letters of each state name)\n",
    "    raw_labor_data[\"State\"] = raw_labor_data[\"State\"].apply(lambda state_name: us_state_to_abbrev[state_name])\n",
    "\n",
    "    #Original raw data has different columns stacked on top of each row, so we need to reorder the dataset.\n",
    "    #Block 1 contains total, constructing and mining data\n",
    "    block1 = raw_labor_data[:50]\n",
    "    block1.columns = [\"State\", \"Total\", \"Constructing\", \"Mining\"]\n",
    "\n",
    "    #Block 2 contains Trade, Financial and Professional\n",
    "    block2 = raw_labor_data[50:100]\n",
    "    block2.columns = [\"State\", \"Trade\", \"Financial\", \"Professional\"]\n",
    "\n",
    "    #Block 3 contains Education, Leisure and Government\n",
    "    block3 = raw_labor_data[100:]\n",
    "    block3.columns = [\"State\", \"Education\", \"Leisure\", \"Gov\"]\n",
    "\n",
    "    #merge all blocks into one dataframe\n",
    "    labor_data = block1.merge(block2, on=\"State\")\n",
    "    labor_data = labor_data.merge(block3, on=\"State\")\n",
    "\n",
    "    #We only need data on white collar and blue collar, so we can combine each job sector to their respective group.\n",
    "    labor_data[\"Blue_col\"] = labor_data[\"Constructing\"] + labor_data[\"Mining\"] + labor_data[\"Trade\"] + labor_data[\"Leisure\"]\n",
    "    labor_data[\"White_col\"] = labor_data[\"Financial\"] + labor_data[\"Professional\"] + labor_data[\"Education\"] + labor_data[\"Gov\"]\n",
    "\n",
    "    #Get rid of all other columns except State, White_col, Blue_col and Total\n",
    "    labor_data.drop(columns = [\"Constructing\", \"Mining\", \"Trade\", \"Financial\", \"Professional\", \"Education\", \"Leisure\", \"Gov\"], inplace=True)\n",
    "    #export as csv\n",
    "    labor_data.columns = ['state','tot_jobs','blue_col','white_col']\n",
    "    labor_data.to_csv('./Cleaned Data/state_labor_data.csv')\n",
    "\n",
    "def get_labor_data():\n",
    "    labor_data_url = './Cleaned Data/state_labor_data.csv'\n",
    "    labor_data = pd.read_csv(labor_data_url)\n",
    "    return labor_data\n",
    "\n",
    "clean_labor_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset 3 (Income/Insurance)\n",
    "- For Dataset 3, we have two primary steps in cleaning the data. The first step was manually inputting the data from the data sources to a CSV file via Google Sheets. This manual step was necessary due to the fact that the original data source did not have an option to directly extract/download the raw data. Since there were only 50 observations, we decided manual input was the best option. \n",
    "\n",
    "- Our second step for Dataset 3 was to import the data into this notebook. We uploaded the CSV file into our \"Raw Data\" folder, and then used read_csv to bring it into a dataframe, which is a usable format for our future analysis. After making sure there were no issues, we then saved it to the \"Cleaned Data\" folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3 (Income/Insurance) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_income(string):\n",
    "    string = string.strip()\n",
    "\n",
    "    string = string.replace(',', '')\n",
    "    return float(string)\n",
    "\n",
    "# Cleaning socioeconomic data\n",
    "def clean_socioeconomic_data():\n",
    "    socioeconomic_data_url = r'./Raw Data/socioeconomic_data.csv'\n",
    "    soci_data = pd.read_csv(socioeconomic_data_url)\n",
    "\n",
    "    #simplify columns and replace Median Household income values with floats\n",
    "    soci_data.columns = ['state', '%_no_insurance', 'median_income']\n",
    "    soci_data['median_income'] = soci_data['median_income'].apply(standardize_income)\n",
    "\n",
    "    soci_data['with_insurance'] = 100 - soci_data['%_no_insurance'] \n",
    "\n",
    "    # Saving to CSV\n",
    "    clean_socioeconomic_data_url = r\"./Cleaned Data/clean_socioeconomic_data.csv\"\n",
    "    soci_data.to_csv(clean_socioeconomic_data_url, index=False)\n",
    "    \n",
    "def get_socioeconomic_data():\n",
    "    clean_socioeconomic_data_url = r\"./Cleaned Data/clean_socioeconomic_data.csv\"\n",
    "    soci_data = pd.read_csv(clean_socioeconomic_data_url)\n",
    "    return soci_data\n",
    "\n",
    "clean_socioeconomic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4 (US population)\n",
    "- The raw data is in csv format with population census data from the US government. For our purposes, we only want the state name and the population in 2020. Although it is 2022, there is not yet a fully released dataset on 2021 population data aside from estimates, so it is fine that we only have 2020 populations and we will be conducting our analysis for 2020.\n",
    "\n",
    "- Since there are also US territories included and DC, we remove those unwanted rows. We also want to store states as their state code rather than their full name. There are also problems with having the population stored as a string, so we do some formatting to make the population be stored as an integer. Finally, we apply some renaming and then our data cleaning is complete.\n",
    "\n",
    "https://data.ers.usda.gov/reports.aspx?ID=17827"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4 (US population) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_population_data():\n",
    "    def format_population(pop: str) -> int:\n",
    "        pop = pop.replace(\",\", \"\")\n",
    "        return int(pop)\n",
    "    # get population data\n",
    "    population_data_url = r\"Raw Data/PopulationReport.csv\"\n",
    "    pop_data = pd.read_csv(population_data_url)\n",
    "    \n",
    "    # keep only state name and total population 2020\n",
    "    pop_data = pop_data[[\"Name\", \"Pop. 2020\"]]\n",
    "    \n",
    "    # Remove unwanted Rows\n",
    "    remove_rows = [\"United States\", \"District of Columbia\", \"Puerto Rico\", \"Source: U.S. Census Bureau, 1990, 2000, 2010, 2020 Censuses of Population\\n\\n\\n\"]\n",
    "    pop_data = pop_data[~pop_data[\"Name\"].isin(remove_rows)]\n",
    "    pop_data.dropna(inplace=True)\n",
    "    \n",
    "    # Change column name\n",
    "    pop_data.columns = [\"state\", \"total_population\"]\n",
    "    \n",
    "    # Value formatting\n",
    "    pop_data[\"total_population\"] = pop_data[\"total_population\"].apply(format_population)\n",
    "    pop_data[\"state\"] = pop_data[\"state\"].apply(to_state_code)\n",
    "    \n",
    "    # save to cleaned data\n",
    "    cleaned_population_data_url = \"Cleaned Data/population.csv\"\n",
    "    pop_data.to_csv(cleaned_population_data_url, index=False)\n",
    "    \n",
    "def read_population_data():\n",
    "    cleaned_population_data_url = \"Cleaned Data/population.csv\"\n",
    "    pop_data = pd.read_csv(cleaned_population_data_url)\n",
    "    return pop_data\n",
    "\n",
    "clean_population_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our EDA involves both univariate and multivariate data-viz techniques. The following is a brief summary of our EDA, but the comments scattered throughout the code are helpful to understand our results. One important thing to note is that for the COVID data, we added up the number of cases and infections throughout the 2020 year to get the proper counts. On the other hand, our other 3 datasets are instantaneously recorded, showing a snapshot of one point in time that represents 2020.\n",
    "\n",
    "### Size\n",
    "At the end of our data cleaning, we ended up with 4 dataframes with 50 rows each. The rows were made unique by their state identifier. The state identifiers are two-letter abberviations of the state that each row represents. We used these 4 dataframes and merged them into one using the following functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatPreZero(num: int) -> str:\n",
    "\n",
    "    #adds '0' char to any integer less than 10 to match formatting\n",
    "    if num >= 10:\n",
    "        return str(num)\n",
    "    \n",
    "    return \"0\" + str(num)\n",
    "    \n",
    "#reformat date parameter to match data values in csv    \n",
    "def formatDate(month: int,  day: int, year: int) -> str:\n",
    "    return f\"{year}/{formatPreZero(month)}/{formatPreZero(day)}\"\n",
    "\n",
    "def read_covid_data(month: int, day: int, year: int):\n",
    "    #retrieve cleaned csv\n",
    "    covid_data_url = r\"Cleaned Data/state_covid_data.csv\"\n",
    "    covid_data = pd.read_csv(covid_data_url)\n",
    "    \n",
    "    #reformat date parameter to match data values in csv, then get all data from specific date\n",
    "    date_filter = formatDate(month, day, year)\n",
    "    covid_data = covid_data[covid_data[\"submission_date\"] == date_filter]\n",
    "    covid_data.sort_values(\"state\", inplace=True)\n",
    "    covid_data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return covid_data\n",
    "\n",
    "def get_labor_data():\n",
    "    labor_data_url = 'Cleaned Data/state_labor_data.csv'\n",
    "    labor_data = pd.read_csv(labor_data_url)\n",
    "    return labor_data\n",
    "\n",
    "def get_socioeconomic_data():\n",
    "    clean_socioeconomic_data_url = \"Cleaned Data/clean_socioeconomic_data.csv\"\n",
    "    soci_data = pd.read_csv(clean_socioeconomic_data_url)\n",
    "    return soci_data\n",
    "\n",
    "def get_population_data():\n",
    "    cleaned_population_data_url = r\"Cleaned Data/population.csv\"\n",
    "    pop_data = pd.read_csv(cleaned_population_data_url)\n",
    "    return pop_data\n",
    "\n",
    "def get_overall_data(month: int, day:int, year:int):\n",
    "    covid_data = read_covid_data(month, day, year)\n",
    "    soci_data = get_socioeconomic_data()\n",
    "    labor_data = get_labor_data()\n",
    "    pop_data = get_population_data()\n",
    "\n",
    "    overall_df = pd.merge(labor_data, soci_data, left_on='state', right_on='state')\n",
    "    overall_df = pd.merge(overall_df, covid_data, left_on='state', right_on='state')\n",
    "    overall_df = pd.merge(overall_df, pop_data, left_on=\"state\", right_on=\"state\")\n",
    "    overall_df.drop([\"Unnamed: 0\"], axis=\"columns\", inplace=True)\n",
    "    overall_df.columns = ['state', 'total_jobs', 'blue_collar', 'white_collar', '%_no_insurance', 'median_income', \n",
    "                          '%_with_insurance', 'submission_date', 'total_cases', 'total_deaths', \"total_population\"]\n",
    "\n",
    "\n",
    "    overall_df['%_mortality_rate'] = (overall_df['total_deaths'] / overall_df['total_cases']) * 100\n",
    "    overall_df['%_blue_collar'] = overall_df['blue_collar'] / overall_df['total_jobs'] * 100\n",
    "    overall_df['%_white_collar'] = overall_df['white_collar'] / overall_df['total_jobs'] * 100\n",
    "    overall_df[\"%_infection_rate\"] = (overall_df[\"total_cases\"] / (overall_df[\"total_population\"] - overall_df[\"total_deaths\"])) * 100\n",
    "\n",
    "\n",
    "    overall_df = overall_df[['state', 'total_jobs', 'blue_collar', '%_blue_collar', 'white_collar', '%_white_collar', \n",
    "                            'median_income', '%_no_insurance', '%_with_insurance', 'submission_date', 'total_population', \n",
    "                            'total_cases', 'total_deaths',  '%_mortality_rate', '%_infection_rate']]\n",
    "    return overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define socioeconomic coefficient (prosperity coefficient)\n",
    "def calculate_alpha(median_income, with_insurance, white_labor):\n",
    "    # alpha is the name of our coeff, it takes the three variables and standardizes them, then assigns them equal weight.\n",
    "    alpha = ((((median_income/100000)*0.3333)) + (with_insurance/100)*0.3333 + (white_labor/100)*0.3333)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calling the functions (Consolidating/Combining Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_overall_data\n",
    "overall_df = get_overall_data(2, 1, 2022)\n",
    "\n",
    "# create column for calculated coeffeicients\n",
    "overall_df['coeff'] = calculate_alpha(overall_df['median_income'],overall_df['%_with_insurance'], overall_df['%_white_collar'])\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Quick Note on Missingness\n",
    "None of our required data was missing due to the nature of our source databases. The US Census data requires averages and census information from each state, as well as the CDC. One way we prevented missingness or inconsistency in our data was by eliminating US territories, like Washington DC. However, after the data cleaning portion of our project, we do not have any missing data to deal with.\n",
    "\n",
    "### Shape\n",
    "We conduct a series of data vizualization steps to show what our current data looks like. By the way, now might be a good time to take a look at some of the general stats of our dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df.describe().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have more of the general descriptive stats on here, let's look at some of the relationships we can easily visualize between our independent variables (socioeconomic factors) and our dependent variable (COVID data). We can accomplish this using scatterplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot 1: Relationship between COVID and Median Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot 1 (median_income vs mortality_rate) and (median_income vs infection_rate)\n",
    "\n",
    "#initialize the figure and scatterplots\n",
    "fig = plt.figure(figsize = (30, 10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "a1, b1 = np.polyfit(overall_df['median_income'], overall_df['%_mortality_rate'], 1)\n",
    "a2, b2 = np.polyfit(overall_df['median_income'], overall_df['%_infection_rate'], 1)\n",
    "\n",
    "\n",
    "#integrate data from overall_df/data from all states\n",
    "ax1.scatter(overall_df['median_income'], overall_df['%_mortality_rate'])\n",
    "ax2.scatter(overall_df['median_income'], overall_df['%_infection_rate'])\n",
    "\n",
    "#titles and axis labels\n",
    "ax1.set_title('Median Income vs. Mortality Rate', fontsize = 20)\n",
    "ax1.set_xlabel('Median Income', fontsize = 20)\n",
    "ax1.set_ylabel('Mortality Rate', fontsize = 20)\n",
    "\n",
    "ax2.set_title('Median Income vs. Infection Rate', fontsize = 20)\n",
    "ax2.set_xlabel('Median Income', fontsize = 20)\n",
    "ax2.set_ylabel('Infection Rate', fontsize = 20)\n",
    "\n",
    "ax1.plot(overall_df['median_income'], a1*overall_df['median_income'] + b1)\n",
    "ax2.plot(overall_df['median_income'], a2*overall_df['median_income'] + b2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the scatterplots above contain 50 data points each, with an individual data point representing one state. Thus, the scatterplot on the left contains 50 data points that represent a state's median income and COVID mortality rate while the scatterplot on the right contains 50 data points that represent a state's median income and COVID infection rate. Additionally, no data points are missing as we intentionally chose, cleaned, and analyzed datasets that had data for all 50 states. \n",
    "\n",
    "In the code to generate the scatterplots, we used matplotlib and its scatter function to generate the two scatterplots side-by-side. Additionally, we used numpy (np), specifically np.polyfit(), to create the line of best fit for the two scatterplots. Thus, the scatterplot on the left has a line of best fit to represent the relationship between a state's median income and COVID mortality rate. Similarly, the scatterplot on the right has a line of best fit to represent the relationship between a state's median income and COVID infection rate. \n",
    "\n",
    "Both of the scatterplots show the same negative, moderate trend. The scatterplot on the left shows that as a state's median income increases, its COVID mortality rate decreases. Similarly, the scatterplot on the right shows that as a state's median income increases, its COVID infection rate decreases. Going back to our research question, these two scatterplots do show that there is a negative correlation between a state's median income and COVID mortality and infection rates. However, we cannot prove causation without performing an experiment. \n",
    "\n",
    "One possible explanation for why there is a negative correlation in both scatterplots is that states with higher median incomes means that there are more people with higher incomes. Thus, this higher wealth means that people in these states can afford better healthcare while people in lower-income states might not have access to the same healthcare. Thus, states with a higher median income will tend to have a lower COVID mortality and infection rate since there are more people who can afford healthcare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot 2: Relationship between COVID and Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot 2 (with_insurance vs morality_rate) and (with_insurance vs infection_rate) (wesley)\n",
    "\n",
    "#initialize the figure and scatterplots\n",
    "fig2 = plt.figure(figsize = (35, 15))\n",
    "ax1 = fig2.add_subplot(121)\n",
    "ax2 = fig2.add_subplot(122)\n",
    "\n",
    "a1, b1 = np.polyfit(overall_df['%_with_insurance'], overall_df['%_mortality_rate'], 1)\n",
    "a2, b2 = np.polyfit(overall_df['%_with_insurance'], overall_df['%_infection_rate'], 1)\n",
    "\n",
    "#integrate data from overall_df/data from all states\n",
    "ax1.scatter(overall_df['%_with_insurance'], overall_df['%_mortality_rate'])\n",
    "ax2.scatter(overall_df['%_with_insurance'], overall_df['%_infection_rate'])\n",
    "\n",
    "#titles and axis labels\n",
    "ax1.set_title('Percent of Population with Insurance vs. Mortality Rate', fontsize = 20)\n",
    "ax1.set_xlabel('Percent of Population with Insurance', fontsize = 20)\n",
    "ax1.set_ylabel('Mortality Rate', fontsize = 20)\n",
    "\n",
    "ax2.set_title('Percent of Population with Insurance vs. Infection Rate', fontsize = 20)\n",
    "ax2.set_xlabel('Percent of Population with Insurance', fontsize = 20)\n",
    "ax2.set_ylabel('Infection Rate', fontsize = 20)\n",
    "\n",
    "\n",
    "ax1.plot(overall_df['%_with_insurance'], a1*overall_df['%_with_insurance'] + b1)\n",
    "ax2.plot(overall_df['%_with_insurance'], a2*overall_df['%_with_insurance'] + b2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two scatterplots are very similar to the scatterplots in the previous section that showed a negative correlation between a state's median income and COVID mortality and infection rates. \n",
    "\n",
    "Each of the scatterplots above contain 50 data points each, with an individual data point representing one state. Thus, the scatterplot on the left contains 50 data points that represent a state's percentage of people who have health insurance and COVID mortality rate while the scatterplot on the right contains 50 data points that represent a state's percentage of people who have health insurance and COVID infection rate. Additionally, no data points are missing as we intentionally chose, cleaned, and analyzed datasets that had data for all 50 states. \n",
    "\n",
    "In the code to generate the scatterplots, we used matplotlib and its scatter function to generate the two scatterplots side-by-side. Additionally, we used numpy (np), specifically np.polyfit(), to create the line of best fit for the two scatterplots. Thus, the scatterplot on the left has a line of best fit to represent the relationship between a state's percentage of people who have health insurance and COVID mortality rate. Similarly, the scatterplot on the right has a line of best fit to represent the relationship between a state's percentage of people who have health insurance and COVID infection rate. \n",
    "\n",
    "Both of the scatterplots show the same negative, moderate trend. The scatterplot on the left shows that as a state's percentage of people who have health insurance increases, its COVID mortality rate decreases. Similarly, the scatterplot on the right shows that as a state's percentage of people who have health insurance increases, its COVID infection rate decreases. Going back to our research question, these two scatterplots do show that there is a negative correlation between a state's percentage of people who have health insurance and COVID mortality and infection rates. However, we cannot prove causation without performing an experiment. \n",
    "\n",
    "One possible explanation for why there is a negative correlation in both scatterplots is that states with a higher percentage of people with health insurance means that there are more people with access to healthcare. Thus, this higher access means that people in these states can afford better healthcare and get treated for COVID while people in lower-percentage states might not have access to the same healthcare. Thus, states with a higher percentage of people with health insurance will tend to have a lower COVID mortality and infection rate since there are more people who can access healthcare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot 3: Relationship between COVID and Labor Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot 3 (%_white_collar vs morality_rate) and (%_white_collar vs infection_rate)\n",
    "\n",
    "#initialize the figure and scatterplots\n",
    "fig3 = plt.figure(figsize = (35, 15))\n",
    "ax1 = fig3.add_subplot(121)\n",
    "ax2 = fig3.add_subplot(122)\n",
    "\n",
    "a1, b1 = np.polyfit(overall_df['%_white_collar'], overall_df['%_mortality_rate'], 1)\n",
    "a2, b2 = np.polyfit(overall_df['%_white_collar'], overall_df['%_infection_rate'], 1)\n",
    "\n",
    "#integrate data from overall_df/data from all states\n",
    "ax1.scatter(overall_df['%_white_collar'], overall_df['%_mortality_rate'])\n",
    "ax2.scatter(overall_df['%_white_collar'], overall_df['%_infection_rate'])\n",
    "\n",
    "#titles and axis labels\n",
    "ax1.set_title('Percent of Labor Force in White-Collar Industries vs. Mortality Rate', fontsize = 20)\n",
    "ax1.set_xlabel('Percent White-Collar', fontsize = 20)\n",
    "ax1.set_ylabel('Mortality Rate', fontsize = 20)\n",
    "\n",
    "ax2.set_title('Percent of Labor Force in White-Collar Industries vs Infection Rate', fontsize = 20)\n",
    "ax2.set_xlabel('Percent White-Collar', fontsize = 20)\n",
    "ax2.set_ylabel('Infection Rate', fontsize = 20)\n",
    "\n",
    "ax1.plot(overall_df['%_white_collar'], a1*overall_df['%_white_collar'] + b1)\n",
    "ax2.plot(overall_df['%_white_collar'], a2*overall_df['%_white_collar'] + b2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Scatterplot 4: Relationship Between Alpha Coeff and COVID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clara\n",
    "\n",
    "#initialize the figure and scatterplots\n",
    "fig3 = plt.figure(figsize = (35, 15))\n",
    "ax1 = fig3.add_subplot(121)\n",
    "ax2 = fig3.add_subplot(122)\n",
    "\n",
    "a1, b1 = np.polyfit(overall_df['coeff'], overall_df['%_mortality_rate'],1)\n",
    "a2, b2 = np.polyfit(overall_df['coeff'], overall_df['%_infection_rate'], 1)\n",
    "\n",
    "#integrate data from overall_df/data from all states\n",
    "ax1.scatter(overall_df['coeff'], overall_df['%_mortality_rate'])\n",
    "ax2.scatter(overall_df['coeff'], overall_df['%_infection_rate'])\n",
    "\n",
    "#titles and axis labels\n",
    "ax1.set_title('Socioeconomic Coefficient vs. Mortality Rate', fontsize = 20)\n",
    "ax1.set_xlabel('Socioeconomic Coefficient', fontsize = 20)\n",
    "ax1.set_ylabel('Mortality Rate', fontsize = 20)\n",
    "\n",
    "ax2.set_title('Socioeconomic Coefficient vs Infection Rate', fontsize = 20)\n",
    "ax2.set_xlabel('Socioeconomic Coefficient', fontsize = 20)\n",
    "ax2.set_ylabel('Infection Rate', fontsize = 20)\n",
    "\n",
    "ax1.plot(overall_df['coeff'], a1*overall_df['coeff']+b1)\n",
    "ax2.plot(overall_df['coeff'], a2*overall_df['coeff']+b2)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hm... well now that we've seen the general trends in our data, let's dive into deeper analyses! Here we will begin to understand the variability in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression for mortality rate and all socioeconomic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# 1 day worth of data\n",
    "mortality_regression_data = get_overall_data(3, 12, 2021)\n",
    "mortality_regression_data = mortality_regression_data[[\"%_white_collar\", \"median_income\", \"%_with_insurance\", \"%_mortality_rate\"]]\n",
    "\n",
    "sns.pairplot(mortality_regression_data, kind=\"scatter\")\n",
    "plt.show()\n",
    "\n",
    "mortality_X = mortality_regression_data[[\"%_white_collar\", \"median_income\", \"%_with_insurance\"]]\n",
    "mortality_Y = mortality_regression_data[\"%_mortality_rate\"]\n",
    "\n",
    "mortality_model = linear_model.LinearRegression()\n",
    "mortality_model.fit(mortality_X, mortality_Y)\n",
    "\n",
    "print(mortality_model.coef_)\n",
    "\n",
    "# 23 days worth of data\n",
    "data_points = [\n",
    "    (4, 10, 2020),\n",
    "    (5, 10, 2020),\n",
    "    (6, 10, 2020),\n",
    "    (7, 10, 2020),\n",
    "    (8, 10, 2020),\n",
    "    (9, 10, 2020),\n",
    "    (10, 10, 2020),\n",
    "    (11, 10, 2020),\n",
    "    (12, 10, 2020),\n",
    "    (1, 10, 2021),\n",
    "    (2, 10, 2021),\n",
    "    (3, 10, 2021),\n",
    "    (4, 10, 2021),\n",
    "    (5, 10, 2021),\n",
    "    (6, 10, 2021),\n",
    "    (7, 10, 2021),\n",
    "    (8, 10, 2021),\n",
    "    (9, 10, 2021),\n",
    "    (10, 10, 2021),\n",
    "    (11, 10, 2021),\n",
    "    (12, 10, 2021),\n",
    "    (1, 10, 2022),\n",
    "    (2, 10, 2022)\n",
    "]\n",
    "\n",
    "mortality_regression_data = pd.DataFrame(columns=[\"%_white_collar\", \"median_income\", \"%_with_insurance\", \"%_mortality_rate\"])\n",
    "\n",
    "for point in data_points:\n",
    "    df = get_overall_data(*point)\n",
    "\n",
    "    df = df[[\"%_white_collar\", \"median_income\", \"%_with_insurance\", \"%_mortality_rate\"]]\n",
    "    mortality_regression_data = pd.concat([mortality_regression_data, df], ignore_index=True)\n",
    "    \n",
    "sns.pairplot(mortality_regression_data, kind=\"scatter\")\n",
    "plt.show()\n",
    "\n",
    "mortality_X = mortality_regression_data[[\"%_white_collar\", \"median_income\", \"%_with_insurance\"]]\n",
    "mortality_Y = mortality_regression_data[\"%_mortality_rate\"]\n",
    "\n",
    "mortality_model = linear_model.LinearRegression()\n",
    "mortality_model.fit(mortality_X, mortality_Y)\n",
    "\n",
    "print(mortality_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least Square for Mortaility Rate and Socioeconomic Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       %_mortality_rate   R-squared:                       0.042\n",
      "Model:                            OLS   Adj. R-squared:                  0.022\n",
      "Method:                 Least Squares   F-statistic:                     2.086\n",
      "Date:                Fri, 25 Feb 2022   Prob (F-statistic):              0.155\n",
      "Time:                        01:24:52   Log-Likelihood:                -32.172\n",
      "No. Observations:                  50   AIC:                             68.34\n",
      "Df Residuals:                      48   BIC:                             72.17\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0272      0.019      1.444      0.155      -0.011       0.065\n",
      "const         -0.7311      1.692     -0.432      0.668      -4.133       2.670\n",
      "==============================================================================\n",
      "Omnibus:                        0.997   Durbin-Watson:                   2.128\n",
      "Prob(Omnibus):                  0.607   Jarque-Bera (JB):                0.357\n",
      "Skew:                           0.114   Prob(JB):                        0.837\n",
      "Kurtosis:                       3.346   Cond. No.                     2.29e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.29e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Q-Q plot')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "mortality_OLS_data = get_overall_data(3, 12, 2021)\n",
    "\n",
    "mortality_X = mortality_OLS_data[[\"%_white_collar\", \"median_income\", \"%_with_insurance\"]]\n",
    "mortality_OLS_Y = mortality_OLS_data[\"%_mortality_rate\"]\n",
    "\n",
    "ones = np.ones(mortality_X.shape[0])\n",
    "mortality_OLS_X = sm.add_constant(np.column_stack((mortality_OLS_data[\"%_white_collar\"], ones)))\n",
    "mortality_OLS_X = sm.add_constant(np.column_stack((mortality_OLS_data[\"median_income\"], ones)))\n",
    "mortality_OLS_X = sm.add_constant(np.column_stack((mortality_OLS_data[\"%_with_insurance\"], ones)))\n",
    "\n",
    "results = sm.OLS(mortality_OLS_Y, mortality_OLS_X).fit()\n",
    "print(results.summary())\n",
    "fig2 = sm.qqplot(results.resid, line='r')\n",
    "plt.title(\"Q-Q plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression for infection rate and socioeconomic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# 1 day worth of data\n",
    "infection_regression_data = get_overall_data(3, 12, 2021)\n",
    "infection_regression_data = infection_regression_data[[\"%_white_collar\", \"median_income\", \"%_with_insurance\", \"%_infection_rate\"]]\n",
    "\n",
    "sns.pairplot(infection_regression_data, kind=\"scatter\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "infection_X = infection_regression_data[[ \"%_white_collar\", \"median_income\", \"%_with_insurance\"]]\n",
    "infection_Y = infection_regression_data[\"%_infection_rate\"]\n",
    "\n",
    "infection_model = linear_model.LinearRegression()\n",
    "infection_model.fit(infection_X, infection_Y)\n",
    "\n",
    "print(infection_model.coef_)\n",
    "\n",
    "infection_regression_data = pd.DataFrame(columns=[\"%_white_collar\", \"median_income\", \"%_with_insurance\", \"%_infection_rate\"])\n",
    "\n",
    "for point in data_points:\n",
    "    df = get_overall_data(*point)\n",
    "    df = df[[ \"%_white_collar\", \"median_income\", \"%_with_insurance\", \"%_infection_rate\"]]\n",
    "    infection_regression_data = pd.concat([infection_regression_data, df], ignore_index=True)\n",
    "    \n",
    "sns.pairplot(infection_regression_data, kind=\"scatter\")\n",
    "plt.show()\n",
    "\n",
    "infection_X = infection_regression_data[[\"%_white_collar\", \"median_income\", \"%_with_insurance\"]]\n",
    "infection_Y = infection_regression_data[\"%_infection_rate\"]\n",
    "\n",
    "infection_model = linear_model.LinearRegression()\n",
    "infection_model.fit(infection_X, infection_Y)\n",
    "\n",
    "print(infection_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "infection_regression_data = get_overall_data(3, 12, 2021)\n",
    "infection_regression_data = infection_regression_data[[\"%_white_collar\", \"median_income\", \"%_with_insurance\", \"%_infection_rate\"]]\n",
    "\n",
    "#alternate linear regression approach\n",
    "#formula = \"\"\"Q('%_infection_rate') ~ Q('%_white_collar')\"\"\"\n",
    "\n",
    "#Multivariate analsysi of infection rate with white collar, median income, and with_insurance data.\n",
    "formula = \"\"\"Q('%_infection_rate') ~ Q('%_white_collar') + Q('median_income') + Q('%_with_insurance')\"\"\"\n",
    "data = infection_regression_data\n",
    "dep, predictors = patsy.dmatrices(formula, data)\n",
    "model = sm.OLS(dep, predictors)\n",
    "res_1 = model.fit()\n",
    "print(res_1.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Best Part\n",
    "One of our biggest goals coming into this project was to be able to create a predictive script that took socioeconomic factors and created a predicted morality and infection rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(median_income, with_insurance, white_collar, desired_output):\n",
    "    coeff = calculate_alpha(median_income, with_insurance, white_collar)\n",
    "    predicted_mortality = a1*coeff+b1\n",
    "    predicted_infection = a2*coeff+b2\n",
    "    if desired_output == 'mortality_rate':\n",
    "        output = predicted_mortality\n",
    "        output = f'{desired_output} = {output} %'\n",
    "    if desired_output == 'infection_rate':\n",
    "        output = predicted_infection\n",
    "        output = f'{desired_output} = {output} %'\n",
    "    if desired_output == 'both':\n",
    "        output = [predicted_mortality,predicted_infection]\n",
    "        output = f'mortality_rate = {output[0]}% \\ninfection_rate = {output[1]}%'\n",
    "    return(output)\n",
    "\n",
    "# Hello user! Feel free to input any values into the prediction function to see what your \"hypothetic state\" would output for mortality rate and infection rate.\n",
    "# The first parameter is the median income, second is the % of people w insurance, and the third is the % of workers who fall under white collar work\n",
    "# The last parameter is whether you want to predict infection or mortality rate. Have fun! Max median income is 100,000.\n",
    "\n",
    "# user_input = prediction(0, 0, 0, 'mortality_rate')\n",
    "# print(user_input)\n",
    "\n",
    "#AN EXAMPLE!\n",
    "clarafornia = prediction(100000, 90, 50, 'both')\n",
    "# print(clarafornia)\n",
    "\n",
    "ernestopia = prediction(2, 2, 2, 'both')\n",
    "print(ernestopia)\n",
    "\n",
    "ethantinople = prediction(50000, 20, 40, 'both')\n",
    "\n",
    "wesafrica = prediction(70000, 60, 20, 'both')\n",
    "\n",
    "stephenopolis = prediction(100000,100,100,'both')\n",
    "# print(stephenopolis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
