{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Stephen Kim\n",
    "- Clara Yi\n",
    "- Ethan Lee\n",
    "- Ernest Lin\n",
    "- Wesley Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the macroscopic socioeconomic features of a state, specifically median income, percentage of population without health insurance, and labor breakdown, have a correlation to COVID mortality rate in 2020-2021?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Dataset 1\n",
    "\n",
    "- Dataset Name: United States COVID-19 Cases and Deaths by State over Time\n",
    "- Link to the dataset: https://data.cdc.gov/Case-Surveillance/United-States-COVID-19-Cases-and-Deaths-by-State-o/9mfq-cb36/data\n",
    "- Number of observations: 44,280 rows, 15 columns, 664,200 observations total\n",
    "\n",
    "This dataset contains the United States (and underlying US territories) data for its COVID rates over time. Such rates include total cases, new cases, total deaths, new deaths, and other metrics that give an overall view of the statistics of COVID for each state. There are submission dates for each row, so that is how we are going to link the rates to specific periods of time\n",
    "\n",
    "### Dataset 2\n",
    "\n",
    "- Dataset Name: Employees on nonfarm payrolls by state and selected industry sector, seasonally adjusted\n",
    "- Link to the dataset: https://www.bls.gov/news.release/laus.t03.htm\n",
    "- Number of observations: 50 rows, 9 columns, 450 observations total\n",
    "\n",
    "Dataset from the US Bureau of Labor Statistics, counting the total number of employees in thousands in the labor force in each state as well as in each of eight industries (construction, manufacturing, trade/transportation/utilities, finance, services, education/health, leisure/hospitality, government).\n",
    "\n",
    "### Dataset 3\n",
    "\n",
    "- Dataset Name: Median Household Income and Percentage of Americans without Health Insurance in 2020\n",
    "- Link to the dataset: https://docs.google.com/spreadsheets/d/174jFoW8KsXGJmpNUx8cbh6j4l6rhQhpOUKIPnkzk3lM/edit#gid=0\n",
    "- Number of observations: 50 rows, 2 columns, 100 observations total\n",
    "\n",
    "This dataset contains the United States' for the median household income and percentage of Americans without Health Insurance in 2020. This data was taken from two different sources, [United States Census Bureau Website](https://www.census.gov/quickfacts/fact/map/CA/HEA775220) and [Federal Reserve Economic Data](https://fred.stlouisfed.org/release/tables?rid=249&eid=259515&od=2020-01-01#), and all of this data was manually imported into a Google SHeet that was converted to a CSV file. \n",
    "\n",
    "### Merging Data\n",
    "Since we are using 3 different primary datasets, we will identify each state with a unique code (California would be CA, Missouri would be MO, etc.). Ultimately, we will merge the datasets during our analysis, with several rows of data for each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning (Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your data cleaning steps here.\n",
    "## Dataset 1\n",
    "- With the imported data, we removed unncessary states. We only want the 50 states not including territories or DC\n",
    "- We then removed the columns that we didn't need for analysis. We did this by selecting the columns that we needed\n",
    "- We also wanted the dates to appear in a sortable/searchable way, so we made the dates arranged in yyyy-mm-dd format\n",
    "**Note**: Since the data is arranged by date, we created a function ```read_covid_data``` that will return the 50 states with their respective data for just that specified date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Dataset 3, we have two primary steps in cleaning the data. The first step, which was manually inputting the data from the data sources to a CSV file via Google Sheets. This manual step was necessary due to the fact that the original data source did not have an option to directly extract/download the raw data. Since there were only 50 observations, we decided manual input was the best option. \n",
    "\n",
    "Our second step for Dataset 3 was to import the data into this notebook. We uploaded the CSV file into our \"Raw_Data\" folder, and then used read_csv to bring it into a dataframe, which is a usable format for our future analysis. After making sure there were no issues, we then saved it to the \"Cleaned Data\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning State Data\n",
    "def clean_covid_data():\n",
    "    # Date Closure\n",
    "    def apply_date(date: str) -> str:\n",
    "        split_date = date.split(\"/\")\n",
    "        return \"/\".join([split_date[2], split_date[0], split_date[1]])\n",
    "        \n",
    "    \n",
    "    # Read the data (already in tabular form)\n",
    "    covid_data_url = r\".\\Data\\State Data\\United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv\"\n",
    "    covid_data = pd.read_csv(covid_data_url)\n",
    "    \n",
    "    # States we will not be looking at (These aren't part of the 50 states)\n",
    "    remove_states = [\"RMI\", \"FSM\", \"GU\", \"MP\", \"PW\", \"NYC\", \"PR\", \"AS\", \"VI\", \"DC\"]\n",
    "    covid_data = covid_data[~covid_data[\"state\"].isin(remove_states)]\n",
    "    \n",
    "    # Remove columns we don't need\n",
    "    covid_data = covid_data[[\"submission_date\", \"state\", \"tot_cases\", \"tot_death\"]]\n",
    "    \n",
    "    # Change Date format to allow for easier sorting\n",
    "    covid_data[\"submission_date\"] = covid_data[\"submission_date\"].apply(apply_date)\n",
    "    \n",
    "    # Sort Date\n",
    "    covid_data.sort_values(\"submission_date\", inplace=True, ascending=False)\n",
    "    covid_data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Save Data\n",
    "    clean_covid_data_url = r\".\\Cleaned Data\\state_covid_data.csv\"\n",
    "    covid_data.to_csv(clean_covid_data_url, index=False)\n",
    "    \n",
    "clean_covid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_covid_data(month: int, day: int, year: int):\n",
    "    covid_data_url = r\".\\Cleaned Data\\state_covid_data.csv\"\n",
    "    covid_data = pd.read_csv(covid_data_url)\n",
    "    \n",
    "    date_filter = formatDate(month, day, year)\n",
    "    covid_data = covid_data[covid_data[\"submission_date\"] == date_filter]\n",
    "    covid_data.sort_values(\"state\", inplace=True)\n",
    "    covid_data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return covid_data\n",
    "\n",
    "def formatPreZero(num: int) -> str:\n",
    "    if num >= 10:\n",
    "        return str(num)\n",
    "    \n",
    "    return \"0\" + str(num)\n",
    "    \n",
    "    \n",
    "def formatDate(month: int,  day: int, year: int) -> str:\n",
    "    return f\"{year}/{formatPreZero(month)}/{formatPreZero(day)}\"\n",
    "\n",
    "read_covid_data(3, 15, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning socioeconomic data\n",
    "\n",
    "socioeconomic_data_url = r'./Raw Data/socioeconomic_data.csv'\n",
    "socioeconomic_data = pd.read_csv(socioeconomic_data_url)\n",
    "print(socioeconomic_data)\n",
    "\n",
    "# Saving to GitHub\n",
    "clean_socioeconomic_data_url = r\"./Cleaned Data/clean_socioeconomic_data.csv\"\n",
    "socioeconomic_data.to_csv(clean_socioeconomic_data_url, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
